#配置mysql
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/lin?characterEncoding=utf8&useSSL=true
spring.datasource.username=root
spring.datasource.password=douban

# 下面为连接池的补充设置，应用到上面所有数据源中
# 初始化大小，最小，最大
spring.datasource.initialSize=5
spring.datasource.minIdle=5
spring.datasource.maxActive=20
# 配置获取连接等待超时的时间
spring.datasource.maxWait=60000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.minEvictableIdleTimeMillis=300000
spring.datasource.validationQuery=SELECT 1 FROM DUAL
spring.datasource.testWhileIdle=true
spring.datasource.testOnBorrow=false
spring.datasource.testOnReturn=false
# 打开PSCache，并且指定每个连接上PSCache的大小
spring.datasource.poolPreparedStatements=true
spring.datasource.maxPoolPreparedStatementPerConnectionSize=20
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.filters=stat,wall,log4j
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
# 合并多个DruidDataSource的监控数据
#spring.datasource.useGlobalDataSourceStat=true


mybatis.mapper-locations=classpath*:com/douban/mapper/xml/*.xml
mybatis.type-aliases-package=com.douban.bean

#日志路径  或者  名字必须为 logback-spring.xml
#logging.config=classpath:logback.xml

#邮箱
spring.mail.host=smtp.qq.com
spring.mail.username=949296157@qq.com
spring.mail.password=poiquoskbnxqbeai
spring.mail.default-encoding=utf-8
spring.mail.properties.mail.smtp.auth=true 
spring.mail.properties.mail.smtp.starttls.enable=true
spring.mail.properties.mail.smtp.stattls.required=true

#redis
#spring.redis.host=127.0.0.1
#spring.redis.port=6379
#spring.redis.password=
#spring.redis.database=0
#spring.redis.pool.max-active=8
#spring.redis.pool.max-idle=8
#spring.redis.pool.min-idle=0
#spring.redis.pool.max-wait=-1

#spring.kafka.bootstrap-servers=192.168.31.16:9092
#
#spring.kafka.producer.retries=0
## 每次批量发送消息的数量
#spring.kafka.producer.batch-size=16384
#spring.kafka.producer.buffer-memory=33554432
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.consumer.group-id=group
#spring.kafka.consumer.auto-offset-reset=earliest
#spring.kafka.consumer.enable-auto-commit=true
#spring.kafka.consumer.auto-commit-interval=100
## 指定消息key和消息体的编解码方式
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

management.security.enabled=false
endpoints.shutdown.enabled=true
endpoints.actuator.enabled=true
management.context-path=/monitor
management.port=8088

spring.jackson.date-format=yyyy-MM-dd HH:mm:ss
spring.jackson.time-zone=GMT+8

